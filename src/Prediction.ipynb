{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "- After Preprocessing is fixed remove weird slicing and replace with columns of the ndarray.\n",
    "- For the grid searches don't use CV, but the validation set instead (PreDefinedSplit from sklearn function should do the trick somehow)\n",
    "- Reduce grid search?\n",
    "- Complete evaluation\n",
    "- Create output files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from helper.data_loading import load_subsample\n",
    "from helper.preprocessing import preprocess_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_subsample(\"data/train.csv\")\n",
    "X_train, y_train = preprocess_dataset(train, \"pipeline/pipeline_components.pkl\", load=True)\n",
    "\n",
    "val = load_subsample(\"data/validation.csv\")\n",
    "X_val, y_val = preprocess_dataset(val, \"pipeline/pipeline_components.pkl\", load=True)\n",
    "\n",
    "test = load_subsample(\"data/test.csv\")\n",
    "X_test, y_test = preprocess_dataset(test, \"pipeline/pipeline_components.pkl\", load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When labels are fixed use the columns instead of this weird slicing\n",
    "length = int(len(y_train)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "              'activation': ['tanh', 'relu'],\n",
    "              'solver': ['sgd', 'adam'],\n",
    "              'alpha': [0.0001, 0.05],\n",
    "              'learning_rate': ['constant','adaptive']\n",
    "             }\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "model = MLPClassifier(max_iter=100)\n",
    "\n",
    "# Search of parameters, using 3 fold cross validation, use all available cores\n",
    "mlp = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "# CHANGE TO y_train WHEN IT IS THE CORRECT ND ARRAY, SHOULD PREDICT ALL THE LABELS NOW\n",
    "mlp.fit(X_train, y_train[0:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(mlp.best_params_)\n",
    "best = mlp.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred = best.predict_proba(X_test)\n",
    "y_pred[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "A random grid search is used to find hyperparameters for the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "random_grid = {'n_estimators': [50, 100, 500, 1000, 1500],\n",
    "               'criterion': ['gini', 'entropy'],\n",
    "               'max_depth': [10, 25, 50, 75, 100],\n",
    "               'min_samples_split': [2, 3, 4, 5],\n",
    "               'min_samples_leaf': [1, 2, 3, 4],\n",
    "               'max_features': ['sqrt', 'log2'],\n",
    "               'bootstrap': [True, False]\n",
    "              }\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=100, cv=3, verbose=1, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "rf.fit(X_train, y_train[0:length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(rf.best_params_)\n",
    "best_reply = rf.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_reply = best_reply.predict_proba(X_test)\n",
    "y_pred_reply[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "rf.fit(X_train, y_train[length:length*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(rf.best_params_)\n",
    "best_retweet = rf.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_retweet = best_retweet.predict_proba(X_test)\n",
    "y_pred_retweet[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retweet with comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "rf.fit(X_train, y_train[length*2:length*3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(rf.best_params_)\n",
    "best_comment = rf.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_comment = best_comment.predict_proba(X_test)\n",
    "y_pred_comment[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "rf.fit(X_train, y_train[length*3:length*4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "print(rf.best_params_)\n",
    "best_like = rf.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_like = best_like.predict_proba(X_test)\n",
    "y_pred_like[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
